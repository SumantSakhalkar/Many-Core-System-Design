{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileimport(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        raw_data = list(reader)\n",
    "    features = raw_data.pop(0)\n",
    "    features.remove(\"class\")\n",
    "    targets = [row.pop(0) for row in raw_data]\n",
    "\n",
    "    test1 = len(raw_data[0]) == len(features)\n",
    "    test2 = len(raw_data) == len(targets)\n",
    "    if test1 and test2:\n",
    "        return raw_data, targets, features\n",
    "    else:\n",
    "        print(\"ERROR\")\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyH(prob):\n",
    "    if prob != 0:\n",
    "        entr = -prob * np.log2(prob)\n",
    "        return entr\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_entropy(targets):\n",
    "    \n",
    "    diff = {}\n",
    "    n = len(targets)\n",
    "    for t in targets:\n",
    "        if t not in diff:\n",
    "            diff[t] = 1\n",
    "        else:\n",
    "            diff[t] += 1\n",
    "    entropy = 0\n",
    "    for t in diff:\n",
    "        p = diff[t] / float(n)\n",
    "        entropy += entropyH(p)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infogain(data, classes, feature):\n",
    "    gain = 0\n",
    "    nData = len(data)\n",
    "\n",
    "    # compute all different values in column feature\n",
    "    fi_s = {}\n",
    "    for row in data:\n",
    "        if row[feature] not in fi_s.keys():\n",
    "            fi_s[row[feature]] = 1\n",
    "        else:\n",
    "            fi_s[row[feature]] += 1\n",
    "\n",
    "    for fi in fi_s.keys():\n",
    "        fi_entropy = 0\n",
    "        row_indx = 0\n",
    "        newClasses = {}\n",
    "        classCounts = 0\n",
    "        for row in data:\n",
    "            if row[feature] == fi:\n",
    "                classCounts += 1\n",
    "                if classes[row_indx] in newClasses.keys():\n",
    "                    newClasses[classes[row_indx]] += 1\n",
    "                else:\n",
    "                    newClasses[classes[row_indx]] = 1\n",
    "            row_indx += 1\n",
    "\n",
    "        for aclass in newClasses.keys():\n",
    "            fi_entropy += entropyH(float(newClasses[aclass]) / classCounts)\n",
    "\n",
    "        gain += float(fi_s[fi]) / nData * fi_entropy\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(data, targets, feature, fi):\n",
    "    \n",
    "    new_data = []\n",
    "    new_targets = []\n",
    "    nFeatures = len(data[0])\n",
    "    row_idx = 0\n",
    "    \n",
    "    for row in data:\n",
    "        if row[feature] == fi:\n",
    "            if feature == 0:\n",
    "                new_row = row[1:]\n",
    "            elif feature == nFeatures:\n",
    "                new_row = row[:-1]\n",
    "            else:\n",
    "                new_row = row[:feature]\n",
    "                new_row.extend(row[feature + 1:])\n",
    "\n",
    "            new_data.append(new_row)\n",
    "            new_targets.append(targets[row_idx])\n",
    "        row_idx += 1\n",
    "\n",
    "    return new_targets, new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(data, classes, features):\n",
    "\n",
    "    nData = len(data)\n",
    "    nFeatures = len(features)\n",
    "    # Have reached an empty branch\n",
    "    uniqueT = {}\n",
    "    for aclass in classes:\n",
    "        if aclass in uniqueT.keys():\n",
    "            uniqueT[aclass] += 1\n",
    "        else:\n",
    "            uniqueT[aclass] = 1\n",
    "\n",
    "    default = max(uniqueT, key=uniqueT.get)\n",
    "    if nData == 0 or nFeatures == 0:\n",
    "        return default\n",
    "    elif len(np.unique(classes)) == 1:\n",
    "        # Only 1 class remains\n",
    "        return classes[0]\n",
    "    else:\n",
    "        # Choose which feature is best\n",
    "        totalEntropy = total_entropy(classes)\n",
    "        gain = np.zeros(nFeatures)\n",
    "        for feature in range(nFeatures):\n",
    "            g = infogain(data, classes, feature)\n",
    "            gain[feature] = totalEntropy - g\n",
    "        best = np.argmax(gain)  # index of the best feature\n",
    "        fi_s = np.unique(np.transpose(data)[best])\n",
    "        feature = features.pop(best)    # Feature Name at that \"best\" position\n",
    "        tree = {feature: {}}\n",
    "        # Find the possible feature values\n",
    "        for fi in fi_s:\n",
    "            # Find the datapoints with each feature value\n",
    "            t, d = update(data, classes, best, fi)\n",
    "            # Now recurse to the next level\n",
    "            subtree = buildtree(d, t, features)\n",
    "            # And on returning, add the subtree on to the tree\n",
    "            tree[feature][fi] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(csv_file):\n",
    "    data, targets, features = fileimport(filename=csv_file)\n",
    "    tree = buildtree(data, targets, features)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_output(tree, data_row, features):\n",
    "    if type(tree) is not dict:\n",
    "        return str(tree)\n",
    "    else:\n",
    "        for key in tree.keys():\n",
    "            f_idx = features.index(key)\n",
    "            f_i = data_row[f_idx]\n",
    "            return tree_output(tree[key][f_i], data_row, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(file, tree):\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        raw_data = list(reader)\n",
    "        \n",
    "    features = raw_data.pop(0)\n",
    "    features.remove(\"class\")\n",
    "    targets = [row.pop(0) for row in raw_data]\n",
    "\n",
    "    predval = 0\n",
    "    n = len(raw_data)\n",
    "    row_indx = 0\n",
    "    for row in raw_data:\n",
    "        output = tree_output(tree, row, features)\n",
    "        if output == targets[row_indx]:\n",
    "            \n",
    "            predval += 1\n",
    "        row_indx += 1\n",
    "    \n",
    "    return predval*100/float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------\n",
      "{'odor': {'a': 'e',\n",
      "          'c': 'p',\n",
      "          'f': 'p',\n",
      "          'l': 'e',\n",
      "          'm': 'p',\n",
      "          'n': {'spore-print-color': {'b': 'e',\n",
      "                                      'h': 'e',\n",
      "                                      'k': 'e',\n",
      "                                      'n': 'e',\n",
      "                                      'o': 'e',\n",
      "                                      'r': 'p',\n",
      "                                      'w': {'habitat': {'d': {'gill-size': {'b': 'e',\n",
      "                                                                            'n': 'p'}},\n",
      "                                                        'g': 'e',\n",
      "                                                        'l': {'cap-color': {'c': 'e',\n",
      "                                                                            'n': 'e',\n",
      "                                                                            'w': 'p',\n",
      "                                                                            'y': 'p'}},\n",
      "                                                        'p': 'e',\n",
      "                                                        'w': 'e'}},\n",
      "                                      'y': 'e'}},\n",
      "          'p': 'p',\n",
      "          's': 'p',\n",
      "          'y': 'p'}}\n",
      "-------------------------------------------------------------------\n",
      "Accuracy: 100.0 %\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_file = \"mushrooms_train_updated.csv\"\n",
    "    test_file = \"mushrooms_test_updated.csv\"\n",
    "    \n",
    "#    test_file = pd.read_csv('mushrooms_test_updated.csv')\n",
    "#    train_file = pd.read_csv('mushrooms_train_updated.csv')\n",
    "\n",
    "    tree = train(train_file)\n",
    "    prediction_accuracy = predictor(test_file, tree)\n",
    "    \n",
    "#    with open(\"mushrooms_test_updated.csv\", 'r') as f:\n",
    "#        reader = csv.reader(f)\n",
    "#        raw_data = list(reader)\n",
    "#\n",
    "#    predicted_values = predictval(test_file, tree)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    pprint(tree)\n",
    "    \n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(\"Accuracy:\", prediction_accuracy,\"%\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    \n",
    "#    maxAccuracy = calculateAccuracy(test_file, tree)\n",
    "#    bestTree = copy.deepcopy(tree)\n",
    "#    countOfNodes = bestTree.countNodes(bestTree.root)\n",
    "#    c = 0\n",
    "#\n",
    "#    while c < 10:    \n",
    "#        c += 1\n",
    "#        pruneNum = round(countOfNodes*pruneFactor)\n",
    "#        pruneTree = Tree()\n",
    "#        pruneTree = copy.deepcopy(bestTree)\n",
    "#        postPruning(pruneNum,pruneTree.root)\n",
    "#        temp = calculateAccuracy(dvalidation, pruneTree)\n",
    "#        if temp > maxAccuracy:\n",
    "#\n",
    "#            maxAccuracy = temp\n",
    "#            bestTree = copy.deepcopy(pruneTree)\n",
    "#            countOfNodes = bestTree.countNodes(bestTree.root)\n",
    "#    \n",
    "#    print(\"Accuracy of the model on the training dataset = \" , predictor(test_file, tree) , \"%\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
